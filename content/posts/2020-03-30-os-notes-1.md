---
title: "OS Notes: Memory Management"
date: 2020-03-30T19:33:34+08:00
draft: true
---

## Memory abstraction

### Swapping

Bringing in each process in its entirety, running it for a while, then putting it back on the disk.

![image.png](https://i.loli.net/2020/04/09/jvSwcIfkzeW9lhi.png)

How much memory should be allocated for a process when it is created or swapped is worth making concerns.

#### Memory compaction

When swapping creates multiple holes in memory, it is possible to combine them all into one big one by moving all the processes downward as far as possible. It is usually not done because requiring a lot of CPU time.

### Managing free memory

![image.png](https://i.loli.net/2020/04/09/RYc7UPjiEmQ3Cq6.png)

#### With bitmaps

The size of the allocation unit is an import design issue. The smaller the allocation unit, the larger the bitmap. But if the allocation unit is chosen large, appreciable memory may be wasted in the last unit of the process if the process size if not an exact multiple of the allocation unit.

The main problem is searching a bitmap for a run of a given length is a slow operation.

#### With linked lists

![image.png](https://i.loli.net/2020/04/09/u14NHtPi59jIXlJ.png)

Double-linked list makes it easier to find the previous entry and to see if a merge is possible.

##### First fit

The memory manager scans along the list of segments until if finds a hole that is big enough.

##### Next fit

It works the same way as first fit, except that it keeps track of where it is whenever it finds a suitable hole. The next time it is called to find a hole, it starts searching the list from the place where it left off last time, instead of always at the beginning.

Simulations by Bays (1977) show that next fit gives slightly worse performance than first fit.

##### Best fit

It searches the entire list and takes the smallest hole that is adequate.

FIrst fit and next fit generate large holes on the average because best fit tends to fill up memory with tiny, useless holes.

##### Worst fit

It always takes the largest available hole. However, simulation has shown that worst fit is not a very good idea either.

##### Speed up

Maintaining separate lists for processes and holes. The inevitable price that is paid for this speedup on allocation is the additional complexity and slowdown when deallocating memory.

The hole list may be kept sorted on size, hence first fit and best fit are equally fast, and next fit is pointless.

##### Quick fit

It maintains separate lists for some of the more common sizes requested, hence finding a hole of the required size is extremely fast. But as all schemes that sort by hole size, namely, when a process terminates or is swapped out, finding its neighbors to see if a merge with them is possible is quite expensive.

## Virtual memory

The basic idea behind virtual memory is that each program hasits own address space, which is broken up into chunks called **pages**. Each page is a contiguous range of addresses. These pages are mapped onto physical memory, but not all pages have to be in physical memory at the same time  to run the program.

When virtual memory is used, the virtual addresses go to an MMU (Memory Management Unit) that maps the virtual addresses onto the physical memory addresses. The virtual address space consists of fixed-size units called pages. The corresponding units in the physical memory are called **page frames**. Many processors support multiple page sizes that that can be mixed and matched as the os sees fit. In the actual hardware, a __Present/absent bit__ keeps track of which pages are physically present in the memory.

If the process references an unmapped address, the MMU notices that and causes the CPU to trap to the operating system. This trap is called a __page fault__. The os picks a little-used page frame and writes its contents back to the disk. It then fetches the page that was just referenced into the page frame just freed, changes the map, and restarts the trapped instruction.

![image.png](https://i.loli.net/2020/04/09/uDLmkrsZ4lRh7BQ.png)

### Page tables

The page number is used as an index into the __page table__, yielding the number of the page frame corresponding to that virtual page. In a simple impl, the mapping of virtual addresses onto physical addresses can be summarized as follows: the virtual address is split into a virtual page number and an offset. The virtual page number is used as an index into the page table to find the entry for that virtual page. From the page table entry, the page frame number (if any) is found. THe page frame number is attached to the high-order end of the offset, replacing the virtual page number, to form a physical address that can be sent to the memory.

Mathematically speaking, the page table is a function, with the virtual page number as argument and the physical frame number as result.

#### Structure of an entry

![image.png](https://i.loli.net/2020/04/09/DsEAeqcwdgIS9lH.png)

The _Protection_ bits tell what kinds of access are permitted.

The _Modified_ and _Referenced_ bits keep track of page usage. When a page is written to, the hardware automatically sets the _Modified_ bit. If the page in it has been modified, it must be written back to the disk when the os decdes to reclaim a page frame. The bit is sometimes called the __dirty bit__.

The _Referenced_ bit is set whenever a page is referenced, either for reading or for writing. The bit plays an important role in several of the page replacement algorithms.

The last bit allows caching to be disabled for the page. It's important for pages that map onto device registers rather than memory.

### Speeding up paging

