---
title: "OS Notes: File Systems"
date: 2020-04-13T01:51:54+08:00
---

Some file systems distinguish between upper- and lowercase letters, whereas others do not. UNIX falls in the first category, while the old MS-DOS falls in the other. Windows 95 and Windows 98 both used the MS-DOS file system, called __FAT-16__. Windows 98 introduced some extensions to FAT-16, leading to __FAT-32__, but these two are quite similar. The following sieries of Windows all support both FAT file systems which are really obsolete now. These os also have a much more advanced native file system (__NTFS__) that has different properties. There is also second file system for the server version of Windows 8, known as __ReFS__ (or __Resilient File System__). There is also a new FAT-like file system, named __exFAT__, a Microsoft extension to FAT-32 that is optimized for flash drives and large file systems.

## Implementation

### File-system layout

Most disks can be divided up into one or more partitions, with independent file systems on each partition. Sector 0 of the disk is called __MBR (Master Boot Record)__ and is used to boot the computer. The end of the MBR contains the partion table. This table gives the starting and ending addresses of each partition. One of the partitions in the table is marked as active. When the computer is booted, the BIOS reads in and executes the MBR. The first thing the MBR program does is to locate the active partition, read in its first block, which is called the boot block, and execute it. The program in the boot block loads the os in that partition. For uniformity, every partition contains a boot block even if it does not contain a bootable os.

![image-20200413163505754](https://i.loli.net/2020/04/13/AEjVLSsTpfPumOh.png)

Often the file system contains some of the items shown in the above figure. The first one is the __superblock__, which contains all the key parameters about the file system and is read into memory when the computer is booted or the file system is first touched. Typical information includes a magic number to identify the file-system type, the number of blocks and so on.

### Implementing files

Probably the most importmant issue is keeping track of which disk blocks go with which file. A few of methods are shown as follows.

#### Contiguous allocation

The scheme is to store each file as a contiguous run of disk blocks.

![image-20200413164354592](https://i.loli.net/2020/04/13/jTIJexl5CmDpMiZ.png)

Pros:

- Simple to implement because track of where a file's blocks are is reduced to remember two numbers: the disk address of the first block and the number of blocks.
- The read performance is excellent because the entire file can be read from the disk in a single operation. Only one seek (to the first block) is needed, so data come in at the full bandwidth of the disk.

Cons:

- Over the course of time, the disk is ultimately fragmented. When the disk is filled up, it become necessary to either compact the disk, which is prohibitively expensive, or to reuse the free space in the holes. But when a new file is to be created, it is necessary to know its final size to choose a hole to place it in.

#### Linked-list allocation

The method is to keep each one as a linked list of disk blocks.

![image-20200413165320374](https://i.loli.net/2020/04/13/usLWDEyvdTloicK.png)

Pros: No space is lost to disk fragmentation.

Cons:

- Random access is extremely slow. To get to block _n_, the os has to start at the beginning and read the _n_ - 1 blocks prior to it, one at a time.
- The amount of data source in a block is no longer a power of two because the pointer takes up a few bytes. Reads of the full block size require acquiring and concatenating information from two disk blocks, which generates extra overhead due to the copying.

#### Linked-list allocation using a table in memory

Both disadvantages of the linked-list allocation can be eliminated by taking the pointer word from each disk block and putting it in a table in memory. Following figure shows what the table looks like for the example of the above figure.

![image-20200413171727224](https://i.loli.net/2020/04/13/uAFc5wxzoGrbgOa.png)

Such a table in main memory is called a __FAT (File Allocation Table)__.

Random access is much easier. Although the chain must still be followed to find given offset within the file, the chain is entirely in memory, so it can be followed without making any disk references.

The primary disadvantage is that the entire table must be in memory all the time. With a 1-TB disk and a 1-KB block size, the table will take up 3 GB main memory all the time.

#### I-nodes

Every file is associated with a data structure called an __i-node (index-node)__, which lists the attrs and disk addresses of the file's blocks. Given the i-node, it is possible to find all the blocks of the file.

![image-20200413175003891](https://i.loli.net/2020/04/13/8H9IAb4rnXt37Kw.png)

The i-node need be in memory only when the corresponding file is open. 

The problem with i-nodes is that if each one has room for a fixed number of disk addresses, it concerns when a file grows beyond the limit. One of the solutions is to replace the last disk address with the address of a block containing more disk-block addresses.

### Implementing directories

The main function of the directory system is to map the name of the file onto the info needed to locate the area. One obvious possibility is to store then directly in the directory entry, as shown in the following figure.

![image-20200413182116768](https://i.loli.net/2020/04/13/e7cwGOdykmaC2Nf.png)

In this design, a directory consists of a list of fixed-size entries, one per file, containing a file name, a structure of the file attrs, and another disk addresses telling where the disk blocks are.

For the system using i-nodes, another possibility for storing the attrs is to store them in the inodes. Thus the directory entry can be shorter, only with a file name and an i-node number.

Then the problem comes to how to support longer, variable-length file names. Here are two approaches.

![image-20200413183330328](https://i.loli.net/2020/04/13/Ncblw1qDULsu6Zx.png)

The disadvantange of the first method is that when a file is removed, a viriable-sized gap is introduced into the directory, which problem is essentially the same one we saw with contiguous disk files.

For extremely long directories, linear searching can be slow. One way to speed up is to use a hash table. In this way, lookup can be much faster, but administration will be more complex. A different way is to cache the results of searches.

### Shared files

The basic method is to make a copy of the disk addresses of the original file when the file is linked. But changes made by someone will not be visible to the others, thus defeating the purpose of sharing. The problem can be solved in two ways.

In the first solution, disk blocks are in i-node (a little data structure) with the file itself. To make a link, the directory just point to the i-node. When deleting the original file, the only thing to do is remove directory entry, but leave the i-node intact.

The second solution is  to create a new file of type LINK which contains just the path name of the file to which it is linked. This approach is called __symbolic linking__. When the owner removes the file, it is destroyed, and subsequent attempts to access the file via a sumbolic link will fail. However, symbolic links come with extra overhead. The file containing the path must be read, then the path must be parsed and followed, component by component, until the i-node is reached. All theses operations require a considerable number of disk accesses. Furthermore, an extra i-node is needed to for each symbolic link, as is an extra disk block to store the path. One of the advantages is that symbolic links can be used to link to files anywhere in the world, by simply providing the network address.

### Log-structured file systems

The basic idea is to strcture the disk as a great big log. All writes are initially buffered in memory, and periodically all the buffered writes are written to the disk in a single segment, at the end of the log. Opening a file now consists of using the map, which is kept on disk and also cached, to locate the i-node. All of the blocks will be in segments, somewhere in the log.

However, real disks are finite, so eventually the log will occupy the entire disk. To deal with the problem, LFS hasa __cleaner__ thread that scans the log circularly to compact it. It starts out by reading the summary of the first segment in the log to see which i-nodes and files are there. It then checks the i-node map to see if the i-nodes and file blocks are still in use. If not, that information is simply discarded. Else, these i-nodes and blocks go into memory to be written out in the next segment. Consequently, the disk is a big circular buffer.

### Journaling file systems

The basic idea is to keep a log of what the file system is going to do before it does it, so that if the system crashes before it can do its planned work, upon rebooting the system can look in the log to see what was going on at the time of the crash and finish the job. NTFS, ext3 and ReFS all use jounaling.

What the system does is first write a log entry listing the actions to be completed. The log entry is then written to the disk (possibly read back from the disk to verify correctness). Only after the log entry has been written, do the various operations begin. After the operations complete successfully, the log entry is erased.

To make this work, the logged operations must be __idempotent__. And for added reliability, the system can introduce the database concept of an __atomic transaction__.

### Virtual file systems

Most UNIX systems have used the concept of a __VFS (virtual file system)__ to try to integrate multiple file systems into an orderly structure.